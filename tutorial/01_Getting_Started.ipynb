{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae2c8fd3734c812",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ff0241bf48627",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from healnet.models import HealNet\n",
    "from healnet.etl import MMDataset\n",
    "import torch\n",
    "import einops\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from typing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de637307d506881",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Synthetic data example\n",
    "\n",
    "To illustrate how HEALNet can be used in any pipeline, we create three synthetic modalities, i.e., three possible modalities: \n",
    "\n",
    "* Tabular data: `(1, 2000)`\n",
    "    * Table with with 2000 features `tab_d`. For 1D modalities, we add a channel dimension with `tab_c=1`\n",
    "* 2D Image: `(224, 224, 3)`\n",
    "    * Image corresponding to height, width, and colour channel. \n",
    "* 3D Image: `(12, 224, 224, 4)`\n",
    "    * Image dims corresponding to depth, height, weight, and colour channel\n",
    "* Target: `(n, )`\n",
    "    * Asusming `n` observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233819ff1c11e04a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 100 # number of samples\n",
    "b = 4 # batch size\n",
    "\n",
    "# latent channels x dims\n",
    "l_c = 16\n",
    "l_d = 16\n",
    "\n",
    "# 2D image\n",
    "img_c = 3 # image channels\n",
    "h = 224 # image height\n",
    "w = 224 # image width\n",
    "# 3D image\n",
    "d = 12 # depth\n",
    "\n",
    "# 1D tabular\n",
    "tab_c = 1 # tabular channels\n",
    "tab_d = 5000 # tabular features\n",
    "# \n",
    "n_classes = 4 # classification\n",
    "\n",
    "tab_tensor = torch.rand(size=(n, tab_c, tab_d)) \n",
    "img_2d_tensor = torch.rand(size=(n, h, w, img_c))\n",
    "img_3d_tensor = torch.rand(size=(n, d, h, w, img_c))\n",
    "\n",
    "\n",
    "# derive a target\n",
    "target = torch.rand(size=(n,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa2ddc",
   "metadata": {},
   "source": [
    "Given the original data as tensors, we instantiate `MMDataset`, a lightweight wrapper for the torch `Dataset` and pass this into a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df31a7b4a69e7aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = MMDataset([tab_tensor, img_2d_tensor, img_3d_tensor], target)\n",
    "train, test, val = torch.utils.data.random_split(data, [0.7, 0.15, 0.15]) # create 70-15-15 train-val-test split\n",
    "\n",
    "loader_args = {\n",
    "    \"shuffle\": True, \n",
    "    \"batch_size\": 16, \n",
    "}\n",
    "\n",
    "train_loader = DataLoader(train, **loader_args)\n",
    "val_loader = DataLoader(val, **loader_args)\n",
    "test_loader = DataLoader(test, **loader_args)\n",
    "# fetch batch \n",
    "\n",
    "[tab_sample, img_sample_2d, img_sample_3d], target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409a237",
   "metadata": {},
   "source": [
    "### Instantiate HEALNet\n",
    "\n",
    "The non-optional arguments to instantiate HEALNet are: \n",
    "\n",
    "* **n_modalities** (int): Maximum number of modalities for forward pass. Note that fewer modalities can be passed if modalities for individual samples are missing (see `.forward()`)\n",
    "*  **channel_dims** (List[int]): Number of channels or tokens for each modality. Length must match ``n_modalities``. The channel_dims are non-spatial dimensions where positional encoding is not required. \n",
    "* **num_spatial_axes** (List[int]): Spatial axes for each modality.The each spatial axis will be assigned positional encodings, so that ``num_spatial_axis`` is 2 for 2D images, 3 for Video/3D images. \n",
    "* **out_dims** (int): Output shape of task-specific head. Forward pass returns logits of this shape. \n",
    "\n",
    "\n",
    "As such, the input for each modality should be of shape ``(b, (*spatial_dims) c)``, where ``c`` corresponds to the dimensions where positional encoding does not matter (e.g., color channels, set-based features, or tabular features). The `spatial_dims` are the dimensions where preserving structural signal is crucial for the model to learn (e.g., the height x width x depth of the 3D image). \n",
    "\n",
    "#### On tabular modalities\n",
    "\n",
    "One common exception to this are tabular modalities. Many tabular modalities do not contain inherent structure and are just an unordered bag of features. In this case, positional encodings add noise (as they don't mean anything. Therefore, we encode this as 2000 channels. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cae638",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d15c029cf68e0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_axes=[1, 2, 3], channels=[5000, 3, 3]\n",
      "HealNet(\n",
      "  (layers): ModuleList(\n",
      "    (0-2): 3 x ModuleList(\n",
      "      (0): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=5005, out_features=1024, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=64, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm_context): LayerNorm((5005,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "            (3): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=13, out_features=1024, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=64, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm_context): LayerNorm((13,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "            (3): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): PreNorm(\n",
      "        (fn): Attention(\n",
      "          (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
      "          (to_kv): Linear(in_features=18, out_features=1024, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (to_out): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=64, bias=True)\n",
      "            (1): LeakyReLU(negative_slope=0.01)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm_context): LayerNorm((18,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): PreNorm(\n",
      "        (fn): FeedForward(\n",
      "          (net): Sequential(\n",
      "            (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            (1): SELU()\n",
      "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "            (3): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): ModuleList(\n",
      "        (0): PreNorm(\n",
      "          (fn): Attention(\n",
      "            (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
      "            (to_kv): Linear(in_features=64, out_features=1024, bias=False)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=512, out_features=64, bias=True)\n",
      "              (1): LeakyReLU(negative_slope=0.01)\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): PreNorm(\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "              (1): SELU()\n",
      "              (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "              (3): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_logits): Sequential(\n",
      "    (0): Reduce('b n d -> b d', 'mean')\n",
      "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "spatial_axes = []\n",
    "channels = []\n",
    "for tensor in [tab_sample, img_sample_2d, img_sample_3d]:\n",
    "    b, *spatial_dims, c = tensor.shape\n",
    "    spatial_axes.append(len(spatial_dims))\n",
    "    channels.append(c)\n",
    "    \n",
    "print(f\"{spatial_axes=}, {channels=}\")\n",
    "\n",
    "model = HealNet(\n",
    "            n_modalities=3, \n",
    "            channel_dims=channels, # (5000 (tabular), 3 (2 D img), 3 (2D image))\n",
    "            num_spatial_axes=spatial_axes, # spatial/temporal tensor dimensions\n",
    "            out_dims = n_classes,  \n",
    "            l_d=l_d, \n",
    "            l_c=l_c, \n",
    "            fourier_encode_data=True, \n",
    "        )\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e77fe00f07c904",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forward pass\n",
    "logits = model([tab_sample, img_sample_2d, img_sample_3d])\n",
    "latent = model([tab_sample, img_sample_2d, img_sample_3d], return_embeddings=True)\n",
    "\n",
    "assert logits.shape == (b, n_classes)\n",
    "assert latent.shape == (b, l_c, l_d)\n",
    "\n",
    "print(f\"{tab_sample.shape=}\")\n",
    "print(f\"{img_sample_2d.shape=}\")\n",
    "print(f\"{img_sample_3d.shape=}\")\n",
    "print(f\"{logits.shape=}\")\n",
    "print(f\"{latent.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9452f27",
   "metadata": {},
   "source": [
    "## Handling missing modalities\n",
    "\n",
    "HEALNet natively handles missing modalities through its iterative architecture. If you encounter a missing data point in your pipeline, you can simply skip it by passing in `None` instead of the tensor. The model will stil return the embedding or prediction based on the present modalities. \n",
    "\n",
    "Note that `verbose=True` will log during each forward pass, so it's recommended to turn this off in the train loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing modalities indices: [1]\n",
      "Skipping update in fusion layer 1 for missing modality 2\n",
      "Skipping update in fusion layer 2 for missing modality 2\n",
      "Skipping update in fusion layer 3 for missing modality 2\n",
      "Missing modalities indices: [0, 2]\n",
      "Skipping update in fusion layer 1 for missing modality 1\n",
      "Skipping update in fusion layer 1 for missing modality 3\n",
      "Skipping update in fusion layer 2 for missing modality 1\n",
      "Skipping update in fusion layer 2 for missing modality 3\n",
      "Skipping update in fusion layer 3 for missing modality 1\n",
      "Skipping update in fusion layer 3 for missing modality 3\n"
     ]
    }
   ],
   "source": [
    "logits_missing = model([tab_sample, None, img_sample_3d], verbose=True)\n",
    "latent_missing = model([None, img_sample_2d, None], return_embeddings=True, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
