{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-03T15:52:20.515738Z",
     "start_time": "2023-08-03T15:52:12.986939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "if \"x_perceiver\" not in os.listdir():\n",
    "    os.chdir(\"/Users/konsti/Documents/repos/phd/x-perceiver/\")\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from x_perceiver.train import train_loop\n",
    "import einops\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from openslide import OpenSlide\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "    \n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "slide_id = \"TCGA-CF-A9FM-01Z-00-DX1.F9379708-8E04-435E-BF12-8E3222AE728D\"\n",
    "prep_level = 3\n",
    "list_path = Path(f\"data/tcga/wsi/blca/\")\n",
    "\n",
    "patch_coords_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T15:43:02.574619Z",
     "start_time": "2023-08-03T15:43:01.656035Z"
    }
   },
   "id": "b1d0794f902e344c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get max number of patches for fixed-size encoding\n",
    "max_patches = max([patch_coords_dict.get(key).shape[0] for key in patch_coords_dict.keys()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-03T15:43:03.299230Z"
    }
   },
   "id": "8e5a7934ff5e4809"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "file = h5py.File(patch_path, \"r\")\n",
    "coords = file[\"coords\"][:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T11:34:04.003519Z",
     "start_time": "2023-08-03T11:34:03.765285Z"
    }
   },
   "id": "23e72713c9fe1934"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konsti/opt/anaconda3/envs/cognition/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/konsti/opt/anaconda3/envs/cognition/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "permute",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [53]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m patch \u001B[38;5;241m=\u001B[39m slide\u001B[38;5;241m.\u001B[39mread_region((x, y), prep_level, (\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m))\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# visualize tensor\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mpatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpermute\u001B[49m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m     16\u001B[0m patch_transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[1;32m     17\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mLambda(\u001B[38;5;28;01mlambda\u001B[39;00m image: image\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)), \u001B[38;5;66;03m# need to convert to RGB for ResNet encoding\u001B[39;00m\n\u001B[1;32m     18\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[1;32m     19\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.485\u001B[39m, \u001B[38;5;241m0.456\u001B[39m, \u001B[38;5;241m0.406\u001B[39m], \n\u001B[1;32m     20\u001B[0m                         std\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.229\u001B[39m, \u001B[38;5;241m0.224\u001B[39m, \u001B[38;5;241m0.225\u001B[39m]) \u001B[38;5;66;03m# imagenet normalization\u001B[39;00m\n\u001B[1;32m     21\u001B[0m ])\n\u001B[1;32m     23\u001B[0m patch_processed \u001B[38;5;241m=\u001B[39m patch_transform(patch)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cognition/lib/python3.9/site-packages/PIL/Image.py:517\u001B[0m, in \u001B[0;36mImage.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    515\u001B[0m     deprecate(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage categories\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_animated\u001B[39m\u001B[38;5;124m\"\u001B[39m, plural\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_category\n\u001B[0;32m--> 517\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(name)\n",
      "\u001B[0;31mAttributeError\u001B[0m: permute"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T12:05:16.029939Z",
     "start_time": "2023-08-03T12:05:14.002816Z"
    }
   },
   "id": "786685a51742bcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "patch_encoder = models.Res"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c128e536b2f3dee"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid group (or file) id (invalid group (or file) ID)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m file: \n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(name)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cognition/lib/python3.9/site-packages/h5py/_hl/group.py:499\u001B[0m, in \u001B[0;36mGroup.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    496\u001B[0m \u001B[38;5;129m@with_phil\u001B[39m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m     \u001B[38;5;124;03m\"\"\" Iterate over member names \"\"\"\u001B[39;00m\n\u001B[0;32m--> 499\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__iter__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    500\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_d(x)\n",
      "File \u001B[0;32mh5py/h5g.pyx:477\u001B[0m, in \u001B[0;36mh5py.h5g.GroupID.__iter__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/h5g.pyx:478\u001B[0m, in \u001B[0;36mh5py.h5g.GroupID.__iter__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/h5g.pyx:102\u001B[0m, in \u001B[0;36mh5py.h5g.GroupIter.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/h5g.pyx:336\u001B[0m, in \u001B[0;36mh5py.h5g.GroupID.get_num_objs\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid group (or file) id (invalid group (or file) ID)"
     ]
    }
   ],
   "source": [
    "for name in file: \n",
    "    print(name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T11:24:10.349252Z",
     "start_time": "2023-08-03T11:24:10.057583Z"
    }
   },
   "id": "4b47013fa61e99c1"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dataset identifier (invalid dataset identifier)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoords\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32mh5py/_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cognition/lib/python3.9/site-packages/h5py/_hl/dataset.py:1067\u001B[0m, in \u001B[0;36mDataset.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;129m@with_phil\u001B[39m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1063\u001B[0m     \u001B[38;5;124;03m\"\"\" Create a Numpy array containing the whole dataset.  DON'T THINK\u001B[39;00m\n\u001B[1;32m   1064\u001B[0m \u001B[38;5;124;03m    THIS MEANS DATASETS ARE INTERCHANGEABLE WITH ARRAYS.  For one thing,\u001B[39;00m\n\u001B[1;32m   1065\u001B[0m \u001B[38;5;124;03m    you have to read the whole dataset every time this method is called.\u001B[39;00m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1067\u001B[0m     arr \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m dtype)\n\u001B[1;32m   1069\u001B[0m     \u001B[38;5;66;03m# Special case for (0,)*-shape datasets\u001B[39;00m\n\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m numpy\u001B[38;5;241m.\u001B[39mproduct(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39mnumpy\u001B[38;5;241m.\u001B[39mulonglong) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/cognition/lib/python3.9/site-packages/h5py/_hl/dataset.py:474\u001B[0m, in \u001B[0;36mDataset.shape\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    471\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cache_props[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    473\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m phil:\n\u001B[0;32m--> 474\u001B[0m     shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;66;03m# If the file is read-only, cache the shape to speed-up future uses.\u001B[39;00m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;66;03m# This cache is invalidated by .refresh() when using SWMR.\u001B[39;00m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_readonly:\n",
      "File \u001B[0;32mh5py/h5d.pyx:190\u001B[0m, in \u001B[0;36mh5py.h5d.DatasetID.shape.__get__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/h5d.pyx:191\u001B[0m, in \u001B[0;36mh5py.h5d.DatasetID.shape.__get__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/h5d.pyx:347\u001B[0m, in \u001B[0;36mh5py.h5d.DatasetID.get_space\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid dataset identifier (invalid dataset identifier)"
     ]
    }
   ],
   "source": [
    "np.array(coords)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-03T11:19:57.299786Z",
     "start_time": "2023-08-03T11:19:57.033632Z"
    }
   },
   "id": "8e1ff6e551ff634d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "217ff96b7ccbee16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
