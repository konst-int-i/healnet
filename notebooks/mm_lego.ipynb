{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:51:40.230723Z",
     "start_time": "2023-10-27T14:51:39.678102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "if \"x_perceiver\" not in os.listdir():\n",
    "    os.chdir(\"/home/kh701/pycharm/healnet/\")\n",
    "import torch\n",
    "from torch import nn\n",
    "import multiprocessing\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import einops\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from healnet.models.explainer import Explainer\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "from healnet.utils import Config, flatten_config\n",
    "from healnet.etl import TCGADataset\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "    \n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:51:48.182311Z",
     "start_time": "2023-10-27T14:51:39.778657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 0 missing values with mean\n",
      "Missing values per feature: \n",
      " Series([], dtype: int64)\n",
      "Slides available: 436\n",
      "Omic available: 437\n",
      "Overlap: 436\n",
      "Filtering out 1 samples for which there are no omic data available\n",
      "Dataloader initialised for blca dataset\n",
      "Dataset: BLCA\n",
      "Molecular data shape: (436, 2191)\n",
      "Molecular/Slide match: 436/436\n",
      "Slide level count: 4\n",
      "Slide level dimensions: ((79968, 79653), (19992, 19913), (4998, 4978), (2499, 2489))\n",
      "Slide resize dimensions: w: 1024, h: 1024\n",
      "Sources selected: ['omic']\n",
      "Censored share: 0.539\n",
      "Survival_bin_sizes: {0: 72, 1: 83, 2: 109, 3: 172}\n",
      "Filled 0 missing values with mean\n",
      "Missing values per feature: \n",
      " Series([], dtype: int64)\n",
      "Slides available: 1019\n",
      "Omic available: 1022\n",
      "Overlap: 1019\n",
      "Filtering out 3 samples for which there are no omic data available\n",
      "Dataloader initialised for brca dataset\n",
      "Dataset: BRCA\n",
      "Molecular data shape: (1019, 2922)\n",
      "Molecular/Slide match: 1019/1019\n",
      "Slide level count: 3\n",
      "Slide level dimensions: ((35855, 34985), (8963, 8746), (2240, 2186))\n",
      "Slide resize dimensions: w: 1024, h: 1024\n",
      "Sources selected: ['omic']\n",
      "Censored share: 0.868\n",
      "Survival_bin_sizes: {3: 155, 2: 172, 1: 289, 0: 403}\n"
     ]
    }
   ],
   "source": [
    "# get dataloaders\n",
    "config = Config(\"config/main_gpu.yml\").read()\n",
    "config = flatten_config(config) # TODO - refactor to other \n",
    "\n",
    "blca = TCGADataset(\n",
    "    dataset=\"blca\", \n",
    "    config=config, \n",
    "    level=2, \n",
    "    sources=[\"omic\"]\n",
    ")\n",
    "\n",
    "brca = TCGADataset(\n",
    "    dataset=\"brca\", \n",
    "    config=config, \n",
    "    level=2, \n",
    "    sources=[\"omic\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# get tabular data\n",
    "blca_loader = DataLoader(\n",
    "    blca, \n",
    "    batch_size=1, \n",
    "    shuffle=True, \n",
    "    num_workers=multiprocessing.cpu_count()-1\n",
    ")\n",
    "[sample], censorship, event_time, y_disc = next(iter(blca_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:51:48.625194Z",
     "start_time": "2023-10-27T14:51:48.158921Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 2183])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:51:48.696213Z",
     "start_time": "2023-10-27T14:51:48.628610Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tabular self-supervised pre-training\n",
    "\n",
    "To start with, we want to build and encoder-decoder model which trains a cross-attention unit as the encoder, which can later on be deployed in the iterative model. We then want to benchmark the performance with pan-cancer pre-training vs. without pre-training. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from healnet.models.healnet import Attention, PreNorm\n",
    "\n",
    "class AttentionEncoder(nn.Module): \n",
    "    \"\"\"\n",
    "    Simple encoder that uses fourier encoding, pre-norm and cross-attention to encode the input features into a latent array \n",
    "    of size (num_latents x latent_dim). Takes in both the input tensors as well as a randomly initialised latent \n",
    "    array as the input. \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_channels: int,\n",
    "                 latent: torch.Tensor, \n",
    "                 input_axis: int = 1, \n",
    "                 attn_dropout: float = 0.1,\n",
    "                 num_heads: int = 4, \n",
    "                 num_freq_bands: int=8, \n",
    "                 ):    \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        self.input_axis = input_axis\n",
    "        self.attn_dropout = attn_dropout\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        \n",
    "        # fourier_channels = (input_axis * ((num_freq_bands * 2) + 1))\n",
    "        # input_dim = fourier_channels + input_channels\n",
    "        input_dim = input_channels\n",
    "                \n",
    "        latent_dim = latent.shape[-1] # required for PreNorm layer\n",
    "        # simple single attention unit\n",
    "        enc = PreNorm(latent_dim, Attention(latent_dim, input_dim, heads=num_heads, dim_head=num_heads, dropout=attn_dropout), context_dim=input_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([enc])\n",
    "        \n",
    "    def forward(self, latent: torch.Tensor, context: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Note: context is the data, x is the latent\n",
    "        Args:\n",
    "            latent: \n",
    "            context: \n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            latent = layer(x=latent, context=context)\n",
    "        return latent\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:51:48.793935Z",
     "start_time": "2023-10-27T14:51:48.687876Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The decoder often needs to be different depending on the modality, so let's implement modality-specific decoders while trying to have a relatively general-purpose encoder that we can plug into the pipeline.\n",
    "\n",
    "Note that we may change this later down the line. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T16:21:24.885562Z",
     "start_time": "2023-10-27T16:21:24.819030Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder suited for tabular data. We use the following: \n",
    "    - Skip connections: faster and more stable training\n",
    "    - Batch normalisation: stabilises the activations and speeds up training\n",
    "    - Activation: Output layer to map back to output dimensions, corresponding to the original data dims\n",
    "    Tries to reconstruct the original input given the latent\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim: int, num_latents: int, output_dim: int, method: str = \"dense\"):\n",
    "        super(TabularDecoder, self).__init__()\n",
    "        assert method in [\"dense\", \"conv\"], \"Decoder type not recognised\"\n",
    "        # check that latent_dim is divisible by 4\n",
    "        assert num_latents % 4 == 0, \"Latent dim must be a multiple of 4\"\n",
    "        layers = []\n",
    "        \n",
    "        if method == \"dense\": \n",
    "            \n",
    "            # flatten latent array (batch, num_latents, latent_dim) -> (batch, num_latents * latent_dim)\n",
    "            layers.extend([nn.Flatten()]) \n",
    "            out_dims = [1024, 512, 256] # may refactor as hyperparameter later\n",
    "            \n",
    "            in_dim = latent_dim * num_latents\n",
    "            for idx, out_dim in enumerate(out_dims):\n",
    "                \n",
    "                layers.extend([\n",
    "                    nn.Linear(in_features=in_dim, out_features=out_dim), \n",
    "                    nn.LeakyReLU(), \n",
    "                    # nn.BatchNorm1d(hidden_dim, track_running_stats=True), \n",
    "                    nn.Dropout(0.5)\n",
    "                ])\n",
    "                \n",
    "                in_dim = out_dim # update for next layer\n",
    "            \n",
    "            # final layer to reconstruct output\n",
    "            layers.append(nn.Linear(in_dim, output_dim))\n",
    "        \n",
    "        elif method == \"conv\": \n",
    "            print(latent_dim, num_latents)\n",
    "            layers.extend([\n",
    "                nn.ConvTranspose1d(num_latents, out_channels=int(num_latents/2), kernel_size=4, stride=2, padding=1), \n",
    "                nn.BatchNorm1d(int(num_latents/2)),\n",
    "                nn.LeakyReLU(negative_slope=0.1),\n",
    "                \n",
    "                nn.ConvTranspose1d(int(num_latents/2), out_channels=int(num_latents/4), kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm1d(int(num_latents/4)),\n",
    "                nn.LeakyReLU(negative_slope=0.1),\n",
    "                \n",
    "                # If you added any other ConvTranspose layers, ensure the channel sizes match correctly for those as well.\n",
    "                \n",
    "                nn.Conv1d(int(num_latents/4), out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "            ])\n",
    "        \n",
    "        self.decode = nn.Sequential(*layers)\n",
    "        print(self.decode)\n",
    "        \n",
    "    def forward(self, latent: torch.Tensor):\n",
    "        return self.decode(latent)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, putting it all together in the encoder-decoder model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "class TabPretrainer(nn.Module): \n",
    "    \"\"\"\n",
    "    Encoder-decoder model for pre-training tabular data.\n",
    "    # TODO - refactor abstract base class for initialisations \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 sample: torch.Tensor,\n",
    "                 # input_channels: int,\n",
    "                 latent_shape: List[int],\n",
    "                 input_axis: int = 1,\n",
    "                 attn_dropout: float = 0.1,\n",
    "                 num_heads: int = 4,\n",
    "                 num_freq_bands: int=8,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.input_channels = sample.shape[-1]\n",
    "        self.input_axis = input_axis\n",
    "        self.num_latents, self.latent_dim = latent_shape\n",
    "        # self.latent_dim, self.num_latents = latent_shape\n",
    "        self.attn_dropout = attn_dropout\n",
    "        self.num_heads = num_heads\n",
    "        self.num_freq_bands = num_freq_bands\n",
    "        \n",
    "        \n",
    "        # randomly initialise latent\n",
    "        self.latent = nn.Parameter(torch.randn(self.num_latents, self.latent_dim))\n",
    "        \n",
    "        # encoder\n",
    "        self.encoder = AttentionEncoder(\n",
    "            input_channels=self.input_channels, \n",
    "            latent=self.latent, \n",
    "            input_axis=self.input_axis, \n",
    "            attn_dropout=attn_dropout, \n",
    "            num_heads=num_heads, \n",
    "            num_freq_bands=num_freq_bands\n",
    "        )\n",
    "        \n",
    "        # decoder\n",
    "        self.decoder = TabularDecoder(\n",
    "            latent_dim=self.latent_dim, \n",
    "            num_latents=self.num_latents,\n",
    "            output_dim=self.input_channels,\n",
    "            method=\"conv\"\n",
    "            # method=\"dense\"\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # get batch dim\n",
    "        b = x.shape[0]\n",
    "        \n",
    "        # expand latent to batch size\n",
    "        if len(self.latent.shape) == 2:\n",
    "            self.latent = nn.Parameter(einops.repeat(self.latent, \"n d -> b n d\", b=b))\n",
    "        \n",
    "        # encode\n",
    "        # self.latent.data = self.encoder(latent=self.latent, context=x).data + self.latent.data\n",
    "        # works much better with skip connections\n",
    "        self.latent.data = self.encoder(latent=self.latent, context=x).data \n",
    "        # decode, reconstructed x\n",
    "        rec_x = self.decoder(self.latent)\n",
    "        return rec_x\n",
    "    \n",
    "    def get_latent(self):\n",
    "        return self.latent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T16:21:26.890810Z",
     "start_time": "2023-10-27T16:21:26.838622Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to think about tabular loss functions. Here, we can explore both reconstruction losses and contrastive losses. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class TabularLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Reconstruction loss functions for tabular data. We use two types which are commonly used with continuous data: \n",
    "    - Mean squared error\n",
    "    - Constrastive loss, measured as cosine distance between the original and reconstructed data\n",
    "    We seek to minimise both objectives.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 method: str = \"mse\",\n",
    "                 reduction: str = \"mean\",\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        assert method in [\"mse\", \"contrastive\"], \"Loss type not recognised\"\n",
    "        self.loss_type = method\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        if method == \"mse\":\n",
    "            self.loss = nn.MSELoss(reduction=reduction)\n",
    "        elif method == \"contrastive\":\n",
    "            self.loss = nn.CosineEmbeddingLoss(reduction=reduction)\n",
    "            \n",
    "    def __call__(self, **kwargs):\n",
    "        return self.loss(**kwargs)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T16:21:30.737307Z",
     "start_time": "2023-10-27T16:21:30.671668Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we write a pre-training loop that we can use for pre-training across cancer sites. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2191 2922 1758\n"
     ]
    }
   ],
   "source": [
    "# get overlap between omic columns\n",
    "col1 = blca.omic_df.columns\n",
    "col2 = brca.omic_df.columns\n",
    "print(len(col1), len(col2), len(set(col1).intersection(col2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:51:48.995634Z",
     "start_time": "2023-10-27T14:51:48.933595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "     age  is_female  AAK1_rnaseq  AATK_rnaseq  ABCB1_rnaseq  ABCG2_rnaseq  \\\n0     63          0      -0.6734      -0.4660        0.8401       -0.2222   \n1     66          0       2.4277      -0.3853        0.1104       -0.2183   \n2     66          0       2.4277      -0.3853        0.1104       -0.2183   \n3     69          0       1.1340      -0.4110        0.1572        0.0752   \n4     59          1      -0.5311       0.1418       -0.0998       -0.2493   \n..   ...        ...          ...          ...           ...           ...   \n432   71          0       2.8284       0.9219       -0.4711       -0.1561   \n433   61          1       0.9422       0.2662       -0.5276       -0.3078   \n434   60          1      -0.3000      -0.5301       -0.5559        0.4720   \n435   62          1       3.2208      -0.2592       -0.8130       -0.1423   \n436   65          0      -0.3658      -0.2651        1.5479       -0.2854   \n\n     ABI1_rnaseq  ABL1_rnaseq  ABL2_rnaseq  ACE_rnaseq  ACKR1_rnaseq  \\\n0         2.2318      -0.8171       0.8051     -0.1250       -0.2976   \n1        -0.0952      -0.6255       0.0970     -0.4911       -0.1779   \n2        -0.0952      -0.6255       0.0970     -0.4911       -0.1779   \n3         0.0566      -1.3448      -0.3876      1.0335       -0.3683   \n4        -0.6956      -0.3696      -0.1672     -0.7257       -0.3450   \n..           ...          ...          ...         ...           ...   \n432      -0.7569      -0.0186       2.2843      1.9383       -0.3507   \n433      -0.5164      -0.3653       1.6644      0.4936       -0.3722   \n434       0.0597      -0.1817       3.6724      0.1842       -0.3892   \n435      -1.2421      -1.4423      -0.6631     -0.9650       -0.3868   \n436      -1.0743       3.2052       0.2885     -0.3852        2.6972   \n\n     ACKR3_rnaseq  ACSL3_rnaseq  ACSL6_rnaseq  ACVR1B_rnaseq  ACVR1C_rnaseq  \\\n0          1.2538       -0.3237       -0.1429         0.5258        -0.0748   \n1         -0.4134       -0.1501       -0.1576        -0.3597         0.4555   \n2         -0.4134       -0.1501       -0.1576        -0.3597         0.4555   \n3         -0.3736       -0.3294       -0.1807         0.8215        -0.7729   \n4         -0.1465        0.2727        0.3077         1.3352         2.3315   \n..            ...           ...           ...            ...            ...   \n432       -0.4448       -0.4321       -0.1794        -1.0555        -0.6594   \n433       -0.5500       -0.3539       -0.1324        -1.1019        -0.7735   \n434       -0.6284        0.2315       -0.1468        -1.1972        -0.5964   \n435        1.9972        0.0008       -0.1583        -1.4766        -0.7790   \n436        0.7650       -0.7979       -0.1453        -0.9347        -0.5309   \n\n     ACVR1_rnaseq  ACVR2A_rnaseq  ACVR2B_rnaseq  ACVRL1_rnaseq  ADAM10_rnaseq  \\\n0         -0.2048        -0.3004         0.2998        -0.6414         1.2149   \n1         -1.0758         0.3252         1.7109        -0.5763         2.5860   \n2         -1.0758         0.3252         1.7109        -0.5763         2.5860   \n3         -0.7901        -0.9142        -0.2716        -0.2526         1.2477   \n4          0.2386         1.6382        -0.2124        -0.7441         0.9661   \n..            ...            ...            ...            ...            ...   \n432        1.4145        -1.0607        -0.2349         0.9236        -0.8023   \n433        0.0458        -1.1459        -0.6342         0.4675        -1.0416   \n434       -0.2927        -0.9101        -0.6431        -0.3869        -0.5002   \n435       -1.2992        -1.0639         0.5145        -0.8358        -0.1595   \n436        0.6657        -0.2331        -0.7919         0.7327        -0.7508   \n\n     ADAM17_rnaseq  ADCK1_rnaseq  ADCK2_rnaseq  ADCK5_rnaseq  ...  UTRN_mut  \\\n0           1.1643        0.3720       -0.2883       -0.1974  ...         1   \n1           1.5608       -0.6966        0.1801       -0.3164  ...         0   \n2           1.5608       -0.6966        0.1801       -0.3164  ...         0   \n3           0.8202       -0.1294        0.7846       -0.2564  ...         0   \n4           0.6493       -1.2289       -0.0261       -0.1046  ...         0   \n..             ...           ...           ...           ...  ...       ...   \n432         1.6165       -1.0423       -1.2719       -0.7105  ...         0   \n433        -0.9597       -1.3496        0.4849        1.6007  ...         0   \n434        -0.0913       -0.6892       -0.6854        1.1884  ...         0   \n435        -0.0378       -0.3054        0.7819        1.9629  ...         0   \n436        -0.2766       -0.1653       -0.3842       -0.4158  ...         0   \n\n     VCAN_mut  VPS13B_mut  VPS13C_mut  VPS13D_mut  WDFY3_mut  WNK1_mut  \\\n0           0           0           0           0          0         0   \n1           0           0           0           0          0         0   \n2           0           0           0           0          0         0   \n3           0           0           0           0          0         0   \n4           0           0           0           0          0         0   \n..        ...         ...         ...         ...        ...       ...   \n432         0           0           1           0          0         0   \n433         0           0           0           0          0         0   \n434         0           0           0           0          0         0   \n435         0           0           0           0          0         0   \n436         0           0           0           0          0         0   \n\n     XIRP2_mut  XIST_mut  ZDBF2_mut  ZFHX3_mut  ZFHX4_mut  ZFP36L1_mut  \\\n0            0         0          0          0          1            0   \n1            0         0          0          0          1            0   \n2            0         0          0          0          1            0   \n3            0         0          0          0          0            0   \n4            0         1          0          1          1            0   \n..         ...       ...        ...        ...        ...          ...   \n432          0         0          0          0          0            0   \n433          1         0          0          0          1            0   \n434          0         0          0          0          0            0   \n435          0         0          0          0          0            1   \n436          0         0          0          0          0            0   \n\n     ZFYVE26_mut  ZFYVE9_mut  ZNF236_mut  ZNF292_mut  ZNF423_mut  ZNF521_mut  \\\n0              1           0           0           0           0           0   \n1              0           0           0           0           0           0   \n2              0           0           0           0           0           0   \n3              0           0           0           0           0           0   \n4              0           0           0           0           0           0   \n..           ...         ...         ...         ...         ...         ...   \n432            0           0           0           0           0           0   \n433            0           0           0           0           0           0   \n434            0           0           0           0           0           0   \n435            0           0           0           1           0           0   \n436            0           0           0           0           0           0   \n\n     ZNF536_mut  ZNF626_mut  ZNF804A_mut  ZNF91_mut  ZZEF1_mut  RAS_mut  \n0             0           0            0          0          0        1  \n1             0           0            0          0          0        0  \n2             0           0            0          0          0        0  \n3             0           0            0          0          0        0  \n4             0           1            0          0          0        0  \n..          ...         ...          ...        ...        ...      ...  \n432           0           0            0          0          0        1  \n433           0           1            0          0          0        1  \n434           0           0            0          0          0        0  \n435           0           0            0          0          0        1  \n436           0           0            0          0          0        0  \n\n[436 rows x 2183 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>is_female</th>\n      <th>AAK1_rnaseq</th>\n      <th>AATK_rnaseq</th>\n      <th>ABCB1_rnaseq</th>\n      <th>ABCG2_rnaseq</th>\n      <th>ABI1_rnaseq</th>\n      <th>ABL1_rnaseq</th>\n      <th>ABL2_rnaseq</th>\n      <th>ACE_rnaseq</th>\n      <th>ACKR1_rnaseq</th>\n      <th>ACKR3_rnaseq</th>\n      <th>ACSL3_rnaseq</th>\n      <th>ACSL6_rnaseq</th>\n      <th>ACVR1B_rnaseq</th>\n      <th>ACVR1C_rnaseq</th>\n      <th>ACVR1_rnaseq</th>\n      <th>ACVR2A_rnaseq</th>\n      <th>ACVR2B_rnaseq</th>\n      <th>ACVRL1_rnaseq</th>\n      <th>ADAM10_rnaseq</th>\n      <th>ADAM17_rnaseq</th>\n      <th>ADCK1_rnaseq</th>\n      <th>ADCK2_rnaseq</th>\n      <th>ADCK5_rnaseq</th>\n      <th>...</th>\n      <th>UTRN_mut</th>\n      <th>VCAN_mut</th>\n      <th>VPS13B_mut</th>\n      <th>VPS13C_mut</th>\n      <th>VPS13D_mut</th>\n      <th>WDFY3_mut</th>\n      <th>WNK1_mut</th>\n      <th>XIRP2_mut</th>\n      <th>XIST_mut</th>\n      <th>ZDBF2_mut</th>\n      <th>ZFHX3_mut</th>\n      <th>ZFHX4_mut</th>\n      <th>ZFP36L1_mut</th>\n      <th>ZFYVE26_mut</th>\n      <th>ZFYVE9_mut</th>\n      <th>ZNF236_mut</th>\n      <th>ZNF292_mut</th>\n      <th>ZNF423_mut</th>\n      <th>ZNF521_mut</th>\n      <th>ZNF536_mut</th>\n      <th>ZNF626_mut</th>\n      <th>ZNF804A_mut</th>\n      <th>ZNF91_mut</th>\n      <th>ZZEF1_mut</th>\n      <th>RAS_mut</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>0</td>\n      <td>-0.6734</td>\n      <td>-0.4660</td>\n      <td>0.8401</td>\n      <td>-0.2222</td>\n      <td>2.2318</td>\n      <td>-0.8171</td>\n      <td>0.8051</td>\n      <td>-0.1250</td>\n      <td>-0.2976</td>\n      <td>1.2538</td>\n      <td>-0.3237</td>\n      <td>-0.1429</td>\n      <td>0.5258</td>\n      <td>-0.0748</td>\n      <td>-0.2048</td>\n      <td>-0.3004</td>\n      <td>0.2998</td>\n      <td>-0.6414</td>\n      <td>1.2149</td>\n      <td>1.1643</td>\n      <td>0.3720</td>\n      <td>-0.2883</td>\n      <td>-0.1974</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>66</td>\n      <td>0</td>\n      <td>2.4277</td>\n      <td>-0.3853</td>\n      <td>0.1104</td>\n      <td>-0.2183</td>\n      <td>-0.0952</td>\n      <td>-0.6255</td>\n      <td>0.0970</td>\n      <td>-0.4911</td>\n      <td>-0.1779</td>\n      <td>-0.4134</td>\n      <td>-0.1501</td>\n      <td>-0.1576</td>\n      <td>-0.3597</td>\n      <td>0.4555</td>\n      <td>-1.0758</td>\n      <td>0.3252</td>\n      <td>1.7109</td>\n      <td>-0.5763</td>\n      <td>2.5860</td>\n      <td>1.5608</td>\n      <td>-0.6966</td>\n      <td>0.1801</td>\n      <td>-0.3164</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66</td>\n      <td>0</td>\n      <td>2.4277</td>\n      <td>-0.3853</td>\n      <td>0.1104</td>\n      <td>-0.2183</td>\n      <td>-0.0952</td>\n      <td>-0.6255</td>\n      <td>0.0970</td>\n      <td>-0.4911</td>\n      <td>-0.1779</td>\n      <td>-0.4134</td>\n      <td>-0.1501</td>\n      <td>-0.1576</td>\n      <td>-0.3597</td>\n      <td>0.4555</td>\n      <td>-1.0758</td>\n      <td>0.3252</td>\n      <td>1.7109</td>\n      <td>-0.5763</td>\n      <td>2.5860</td>\n      <td>1.5608</td>\n      <td>-0.6966</td>\n      <td>0.1801</td>\n      <td>-0.3164</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>69</td>\n      <td>0</td>\n      <td>1.1340</td>\n      <td>-0.4110</td>\n      <td>0.1572</td>\n      <td>0.0752</td>\n      <td>0.0566</td>\n      <td>-1.3448</td>\n      <td>-0.3876</td>\n      <td>1.0335</td>\n      <td>-0.3683</td>\n      <td>-0.3736</td>\n      <td>-0.3294</td>\n      <td>-0.1807</td>\n      <td>0.8215</td>\n      <td>-0.7729</td>\n      <td>-0.7901</td>\n      <td>-0.9142</td>\n      <td>-0.2716</td>\n      <td>-0.2526</td>\n      <td>1.2477</td>\n      <td>0.8202</td>\n      <td>-0.1294</td>\n      <td>0.7846</td>\n      <td>-0.2564</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59</td>\n      <td>1</td>\n      <td>-0.5311</td>\n      <td>0.1418</td>\n      <td>-0.0998</td>\n      <td>-0.2493</td>\n      <td>-0.6956</td>\n      <td>-0.3696</td>\n      <td>-0.1672</td>\n      <td>-0.7257</td>\n      <td>-0.3450</td>\n      <td>-0.1465</td>\n      <td>0.2727</td>\n      <td>0.3077</td>\n      <td>1.3352</td>\n      <td>2.3315</td>\n      <td>0.2386</td>\n      <td>1.6382</td>\n      <td>-0.2124</td>\n      <td>-0.7441</td>\n      <td>0.9661</td>\n      <td>0.6493</td>\n      <td>-1.2289</td>\n      <td>-0.0261</td>\n      <td>-0.1046</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>71</td>\n      <td>0</td>\n      <td>2.8284</td>\n      <td>0.9219</td>\n      <td>-0.4711</td>\n      <td>-0.1561</td>\n      <td>-0.7569</td>\n      <td>-0.0186</td>\n      <td>2.2843</td>\n      <td>1.9383</td>\n      <td>-0.3507</td>\n      <td>-0.4448</td>\n      <td>-0.4321</td>\n      <td>-0.1794</td>\n      <td>-1.0555</td>\n      <td>-0.6594</td>\n      <td>1.4145</td>\n      <td>-1.0607</td>\n      <td>-0.2349</td>\n      <td>0.9236</td>\n      <td>-0.8023</td>\n      <td>1.6165</td>\n      <td>-1.0423</td>\n      <td>-1.2719</td>\n      <td>-0.7105</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>61</td>\n      <td>1</td>\n      <td>0.9422</td>\n      <td>0.2662</td>\n      <td>-0.5276</td>\n      <td>-0.3078</td>\n      <td>-0.5164</td>\n      <td>-0.3653</td>\n      <td>1.6644</td>\n      <td>0.4936</td>\n      <td>-0.3722</td>\n      <td>-0.5500</td>\n      <td>-0.3539</td>\n      <td>-0.1324</td>\n      <td>-1.1019</td>\n      <td>-0.7735</td>\n      <td>0.0458</td>\n      <td>-1.1459</td>\n      <td>-0.6342</td>\n      <td>0.4675</td>\n      <td>-1.0416</td>\n      <td>-0.9597</td>\n      <td>-1.3496</td>\n      <td>0.4849</td>\n      <td>1.6007</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>60</td>\n      <td>1</td>\n      <td>-0.3000</td>\n      <td>-0.5301</td>\n      <td>-0.5559</td>\n      <td>0.4720</td>\n      <td>0.0597</td>\n      <td>-0.1817</td>\n      <td>3.6724</td>\n      <td>0.1842</td>\n      <td>-0.3892</td>\n      <td>-0.6284</td>\n      <td>0.2315</td>\n      <td>-0.1468</td>\n      <td>-1.1972</td>\n      <td>-0.5964</td>\n      <td>-0.2927</td>\n      <td>-0.9101</td>\n      <td>-0.6431</td>\n      <td>-0.3869</td>\n      <td>-0.5002</td>\n      <td>-0.0913</td>\n      <td>-0.6892</td>\n      <td>-0.6854</td>\n      <td>1.1884</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>62</td>\n      <td>1</td>\n      <td>3.2208</td>\n      <td>-0.2592</td>\n      <td>-0.8130</td>\n      <td>-0.1423</td>\n      <td>-1.2421</td>\n      <td>-1.4423</td>\n      <td>-0.6631</td>\n      <td>-0.9650</td>\n      <td>-0.3868</td>\n      <td>1.9972</td>\n      <td>0.0008</td>\n      <td>-0.1583</td>\n      <td>-1.4766</td>\n      <td>-0.7790</td>\n      <td>-1.2992</td>\n      <td>-1.0639</td>\n      <td>0.5145</td>\n      <td>-0.8358</td>\n      <td>-0.1595</td>\n      <td>-0.0378</td>\n      <td>-0.3054</td>\n      <td>0.7819</td>\n      <td>1.9629</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>65</td>\n      <td>0</td>\n      <td>-0.3658</td>\n      <td>-0.2651</td>\n      <td>1.5479</td>\n      <td>-0.2854</td>\n      <td>-1.0743</td>\n      <td>3.2052</td>\n      <td>0.2885</td>\n      <td>-0.3852</td>\n      <td>2.6972</td>\n      <td>0.7650</td>\n      <td>-0.7979</td>\n      <td>-0.1453</td>\n      <td>-0.9347</td>\n      <td>-0.5309</td>\n      <td>0.6657</td>\n      <td>-0.2331</td>\n      <td>-0.7919</td>\n      <td>0.7327</td>\n      <td>-0.7508</td>\n      <td>-0.2766</td>\n      <td>-0.1653</td>\n      <td>-0.3842</td>\n      <td>-0.4158</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>436 rows Ã— 2183 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blca.features\n",
    "\n",
    "# types of features\n",
    "# continuous: *_rnaseq, age\n",
    "# categorical: *_mut, *_cnv "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:51:49.133839Z",
     "start_time": "2023-10-27T14:51:48.972577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 256\n",
      "Sequential(\n",
      "  (0): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "  (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): LeakyReLU(negative_slope=0.1)\n",
      "  (3): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "  (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): LeakyReLU(negative_slope=0.1)\n",
      "  (6): Conv1d(64, 1, kernel_size=(1,), stride=(1,))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2183) must match the size of tensor b (128) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[83], line 72\u001B[0m\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;28mprint\u001B[39m(omic)\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;28mprint\u001B[39m(rec_omic)\n\u001B[0;32m---> 72\u001B[0m \u001B[43mpretrain_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblca\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[83], line 52\u001B[0m, in \u001B[0;36mpretrain_loop\u001B[0;34m(data, batch_size)\u001B[0m\n\u001B[1;32m     50\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(input1\u001B[38;5;241m=\u001B[39momic, input2\u001B[38;5;241m=\u001B[39mrec_omic, target\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mones(omic\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m loss_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m\"\u001B[39m: \n\u001B[0;32m---> 52\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43momic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrec_omic\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m# loss = loss_fn(omic, rec_omic)\u001B[39;00m\n\u001B[1;32m     54\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "Cell \u001B[0;32mIn[81], line 23\u001B[0m, in \u001B[0;36mTabularLoss.__call__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/cognition/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.conda/envs/cognition/lib/python3.9/site-packages/torch/nn/modules/loss.py:536\u001B[0m, in \u001B[0;36mMSELoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 536\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmse_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/cognition/lib/python3.9/site-packages/torch/nn/functional.py:3291\u001B[0m, in \u001B[0;36mmse_loss\u001B[0;34m(input, target, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m   3288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3289\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3291\u001B[0m expanded_input, expanded_target \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3292\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mmse_loss(expanded_input, expanded_target, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction))\n",
      "File \u001B[0;32m~/.conda/envs/cognition/lib/python3.9/site-packages/torch/functional.py:74\u001B[0m, in \u001B[0;36mbroadcast_tensors\u001B[0;34m(*tensors)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(tensors):\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(broadcast_tensors, tensors, \u001B[38;5;241m*\u001B[39mtensors)\n\u001B[0;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (2183) must match the size of tensor b (128) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "\n",
    "def pretrain_loop(\n",
    "        data: TCGADataset,\n",
    "        batch_size: int, \n",
    "    ):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        data, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=multiprocessing.cpu_count()-1\n",
    "    )\n",
    "    [omic_sample], _, _, _ = next(iter(loader))   \n",
    "    \n",
    "    \n",
    "    model = TabPretrainer(\n",
    "        sample = omic_sample,\n",
    "        # input_channels=omic_sample.shape[-1], \n",
    "        input_axis=1, \n",
    "        latent_shape=[256, 32], \n",
    "        attn_dropout=0.1, \n",
    "        num_heads=4,\n",
    "        num_freq_bands=8\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    loss_method = \"mse\"\n",
    "    loss_fn = TabularLoss(method=loss_method)\n",
    "    \n",
    "    for epoch in tqdm(range(10)):\n",
    "        for idx, batch in enumerate(loader):\n",
    "            [omic], censorship, event_time, y_disc = batch\n",
    "            omic = omic.to(device)\n",
    "            rec_omic = model(omic)\n",
    "            print(rec_omic.shape)\n",
    "            # print(omic.shape)\n",
    "            if loss_method == \"contrastive\":\n",
    "                # need to pass in larges for contrastive loss\n",
    "                # using torch.ones to ensure that omic and rec_omic are learned as similar representations\n",
    "                # note that this is a slight repurposing of the contrastive loss function\n",
    "                # with this, the loss is just 1-cos(omic, rec_omic)\n",
    "                loss = loss_fn(input1=omic, input2=rec_omic, target=torch.ones(omic.shape[0]))\n",
    "            elif loss_method == \"mse\": \n",
    "                loss = loss_fn(input=omic, target=rec_omic)\n",
    "            # loss = loss_fn(omic, rec_omic)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # print every 10th batch\n",
    "            if idx % 100 == 0:\n",
    "                pass\n",
    "                # print(loss)\n",
    "                # print(omic)\n",
    "                # print(rec_omic)\n",
    "        # print epoch-level stats\n",
    "        print(f\"Epoch {epoch+1} loss: {loss}\")\n",
    "        # final reconstruction\n",
    "        print(omic)\n",
    "        print(rec_omic)\n",
    "        \n",
    "            \n",
    "    \n",
    "pretrain_loop(\n",
    "    data=blca, \n",
    "    batch_size=4)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T16:22:33.323850Z",
     "start_time": "2023-10-27T16:22:31.532135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:53:49.991436Z",
     "start_time": "2023-10-27T14:53:49.862536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:53:50.007237Z",
     "start_time": "2023-10-27T14:53:49.867903Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T14:53:50.008590Z",
     "start_time": "2023-10-27T14:53:49.868624Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
