blca:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
#  l1: 0.0001
  l1: 0.00001671147846564475
  num_freq_bands: 2
  depth: 4
  max_freq: 2.
  num_latents: 19
  latent_dim: 119
  cross_dim_head: 55
  latent_dim_head: 127
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.34563567345663077
  ff_dropout: 0.36265657915338073
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
  snn: True

brca:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.00002870617016750465
  num_freq_bands: 2
  depth: 4
  max_freq: 2.
  num_latents: 27
  latent_dim: 39
  cross_dim_head: 74
  latent_dim_head: 20
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.4500536564266122
  ff_dropout: 0.15122457689514174
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
  snn: True

kirp:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.0001668539779081218
  num_freq_bands: 2
  depth: 2
  max_freq: 2.
  num_latents: 23
  latent_dim: 64
  cross_dim_head: 80
  latent_dim_head: 113
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.10432102687195144
  ff_dropout: 0.3016632300471939
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
  snn: True

ucec:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.0001294342914492292
  num_freq_bands: 2
  depth: 2
  max_freq: 2.
  num_latents: 18
  latent_dim: 53
  cross_dim_head: 104
  latent_dim_head: 51
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.26903403568592693
  ff_dropout: 0.397318691777149
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
  snn: True




#### OLD ####
#blca:
#  output_dims: 4 # refers to n_classes for classification, n_bins for survival
#  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
##  l1: 0.0001
#  l1: 0.0
#  num_freq_bands: 2
#  depth: 2
#  max_freq: 2.
#  num_latents: 4
#  latent_dim: 16
#  cross_dim_head: 16
#  latent_dim_head: 16
#  cross_heads: 1
#  latent_heads: 8
#  attn_dropout: 0.5
#  ff_dropout: 0.5
#  fourier_encode_data: True
#  self_per_cross_attn: 0  # if 0, no self attention at all
#  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
#
#brca:
#  output_dims: 4 # refers to n_classes for classification, n_bins for survival
#  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
#  l1: 0.000078
#  num_freq_bands: 2
#  depth: 4
#  max_freq: 2.
#  num_latents: 8
#  latent_dim: 32
#  cross_dim_head: 34
#  latent_dim_head: 102
#  cross_heads: 1
#  latent_heads: 8
#  attn_dropout: 0.5
#  ff_dropout: 0.5
#  fourier_encode_data: True
#  self_per_cross_attn: 0  # if 0, no self attention at all
#  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
#
#kirp:
#  output_dims: 4 # refers to n_classes for classification, n_bins for survival
#  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
#  l1: 0.0002
#  num_freq_bands: 2
#  depth: 4
#  max_freq: 2.
#  num_latents: 16
#  latent_dim: 104
#  cross_dim_head: 128
#  latent_dim_head: 84
#  cross_heads: 1
#  latent_heads: 8
#  attn_dropout: 0.5
#  ff_dropout: 0.5
#  fourier_encode_data: True
#  self_per_cross_attn: 0  # if 0, no self attention at all
#  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
#
#ucec:
#  output_dims: 4 # refers to n_classes for classification, n_bins for survival
#  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
#  l1: 0.00005
#  num_freq_bands: 2
#  depth: 3
#  max_freq: 2.
#  num_latents: 14
#  latent_dim: 38
#  cross_dim_head: 64
#  latent_dim_head: 64
#  cross_heads: 1
#  latent_heads: 8
#  attn_dropout: 0.5
#  ff_dropout: 0.5
#  fourier_encode_data: True
#  self_per_cross_attn: 0  # if 0, no self attention at all
#  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large