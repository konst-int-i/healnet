blca:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
#  l1: 0.0001
  l1: 0.0
  num_freq_bands: 2
  depth: 2
  max_freq: 2.
  num_latents: 4
  latent_dim: 16
  cross_dim_head: 16
  latent_dim_head: 16
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.5
  ff_dropout: 0.5
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large

brca:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.000078
  num_freq_bands: 2
  depth: 4
  max_freq: 2.
  num_latents: 8
  latent_dim: 32
  cross_dim_head: 34
  latent_dim_head: 102
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.5
  ff_dropout: 0.5
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large

kirp:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.0002
  num_freq_bands: 2
  depth: 4
  max_freq: 2.
  num_latents: 16
  latent_dim: 104
  cross_dim_head: 128
  latent_dim_head: 84
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.5
  ff_dropout: 0.5
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large

ucec:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.00005
  num_freq_bands: 2
  depth: 3
  max_freq: 2.
  num_latents: 14
  latent_dim: 38
  cross_dim_head: 64
  latent_dim_head: 64
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.5
  ff_dropout: 0.5
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large

hnsc:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.0001
  num_freq_bands: 2
  depth: 2
  max_freq: 2.
  num_latents: 4
  latent_dim: 16
  cross_dim_head: 16
  latent_dim_head: 16
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.5
  ff_dropout: 0.5
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large

paad:
  output_dims: 4 # refers to n_classes for classification, n_bins for survival
  class_weights: inverse # one of inverse, inverse_root, None; only relevant for classification, not survival
  l1: 0.0001
  num_freq_bands: 2
  depth: 2
  max_freq: 2.
  num_latents: 4
  latent_dim: 16
  cross_dim_head: 16
  latent_dim_head: 16
  cross_heads: 1
  latent_heads: 8
  attn_dropout: 0.5
  ff_dropout: 0.5
  fourier_encode_data: True
  self_per_cross_attn: 0  # if 0, no self attention at all
  weight_tie_layers: False # share weights between layers if False | KEEP THIS, otherwise model size is quite large
